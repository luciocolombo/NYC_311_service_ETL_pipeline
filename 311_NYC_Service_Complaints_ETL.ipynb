{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637f4adf-7d8e-4ee1-a1bf-02ad24c27f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eada165c-7935-462e-ae63-01dadfa30da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataset is very big and pandas has trouble assigning dtypes to the columns automatically because of bad data quality. We assign dtype=str and cast manually.\n",
    "from ETL.load import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f3a066-b907-4e6c-90b6-b38ad5cb5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove columns that have too many nulls, like max_nulls = 0,5  so 50%\n",
    "from ETL.remove_too_empty_cols import remove_too_empty_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84725741-9c52-42f9-a266-f38437702ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unique IDs. Remove duplicate entries if existing\n",
    "from ETL.remove_duplicated_IDs import remove_duplicated_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0061b87f-84e7-4349-8c94-37f22a12a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ETL.dates_to_datetime import dates_to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1a2f62-a8b6-48b6-a9bd-51081cd5da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ETL.remove_invalid_zip_codes import remove_invalid_zip_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e57d2e5b-f385-4225-aeb1-b4e8b20ac66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ETL.remove_invalid_status import remove_invalid_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61cba4e-102f-4add-a8d3-1c50be7f714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ETL.polish_strings import polish_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe94f78c-746e-43ba-bf07-477c9c2558d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.final_validation import final_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4b555a-c09a-4e28-8bab-59af656dc70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample of the total dataset, with some of the total columns only\n",
      "==>Removing too empty columns: removed {'Intersection Street 1', 'Vehicle Type', 'School or Citywide Complaint', 'Intersection Street 2', 'Ferry Direction', 'Taxi Company Borough', 'Landmark', 'Bridge Highway Name', 'Ferry Terminal Name', 'Bridge Highway Segment', 'Road Ramp', 'Garage Lot Name', 'Bridge Highway Direction', 'Taxi Pick Up Location'}\n",
      "==>No duplicated IDs to remove\n",
      "==>Casting dates as datetime format\n",
      "==>Step check zip codes: removed incident zip codes [nan '00083']\n",
      "==>No invalid status to remove\n",
      "==>All string columns have been standarized\n",
      "==> Correct schema validation with Pandera. Checked nullability, data types, categorical values, and unique IDs.\n",
      "Your data is ready, processed in 0.51 seconds, resulting in 19859 rows and 12 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\device\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandera\\_pandas_deprecated.py:149: FutureWarning: Importing pandas-specific classes and functions from the\n",
      "top-level pandera module will be **removed in a future version of pandera**.\n",
      "If you're using pandera to validate pandas objects, we highly recommend updating\n",
      "your import:\n",
      "\n",
      "```\n",
      "# old import\n",
      "import pandera as pa\n",
      "\n",
      "# new import\n",
      "import pandera.pandas as pa\n",
      "```\n",
      "\n",
      "If you're using pandera to validate objects from other compatible libraries\n",
      "like pyspark or polars, see the supported libraries section of the documentation\n",
      "for more information on how to import pandera:\n",
      "\n",
      "https://pandera.readthedocs.io/en/stable/supported_libraries.html\n",
      "\n",
      "To disable this warning, set the environment variable:\n",
      "\n",
      "```\n",
      "export DISABLE_PANDERA_IMPORT_WARNING=True\n",
      "```\n",
      "\n",
      "  warnings.warn(_future_warning, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    t0 = time.time()\n",
    "    nrows = int(os.getenv(\"NROWS\", \"20000\")) #Selects from real dataset and sample (for github CI deploy)\n",
    "    df = (load(nrows)\n",
    "    .pipe(remove_too_empty_cols,0.5)\n",
    "    .pipe(remove_duplicated_IDs)\n",
    "    .pipe(dates_to_datetime)\n",
    "    .pipe(remove_invalid_zip_codes)\n",
    "    .pipe(remove_invalid_status)\n",
    "    .pipe(polish_strings)\n",
    "    .pipe(final_validation)\n",
    "    )\n",
    "    dt = round(time.time() - t0,2)\n",
    "    print(f'Your data is ready, processed in {dt} seconds, resulting in {df.shape[0]} rows and {df.shape[1]} columns')\n",
    "    df.to_csv('311_NYC_requests_clean.csv')\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338827d-912c-4355-85c7-99f4162d59ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
